{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"exploring_bert.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3.8.9 64-bit ('env': venv)"},"interpreter":{"hash":"d8e8f2e5d0e66e453dd22f7a6e79a5e349fc9b089a0e75cf3c84597ed3ff7539"},"widgets":{"application/vnd.jupyter.widget-state+json":{"5cda119de6b44d7d9f390d352f93dd75":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3b234d0112dd46ba91dcaae28e360fd8","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7377fbb765ac4cdab2ae660cb21af4c0","IPY_MODEL_873b64cdc5ca4d418fc0acdb69863bee"]}},"3b234d0112dd46ba91dcaae28e360fd8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7377fbb765ac4cdab2ae660cb21af4c0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4fadff4913074fabb277dc307fe61788","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":995526,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":995526,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_73944a62dd8544bd8d91314f37378e74"}},"873b64cdc5ca4d418fc0acdb69863bee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ce1efceaf30e4d738e89564a0c0ac520","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 996k/996k [00:00&lt;00:00, 1.92MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_806698f0809e4f93be7c81edb50095a4"}},"4fadff4913074fabb277dc307fe61788":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"73944a62dd8544bd8d91314f37378e74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ce1efceaf30e4d738e89564a0c0ac520":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"806698f0809e4f93be7c81edb50095a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fd7652d730a141bf995493146d54a6ff":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c9878fbbc01e43a089dd19c0e8b8454e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0d0b1b21a3ba402ca8386108fc942026","IPY_MODEL_a76eefa6a3d5481e8989a1a249dff9dc"]}},"c9878fbbc01e43a089dd19c0e8b8454e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0d0b1b21a3ba402ca8386108fc942026":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_169bdfc5f32541e7afe6c624d561af0d","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":29,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":29,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_acb2b071aebb44449c792b9e8b2b36f0"}},"a76eefa6a3d5481e8989a1a249dff9dc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5ecd1f8e698c48088042b436513b6d32","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 29.0/29.0 [00:01&lt;00:00, 28.2B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6714cd2a6ba6406ea041bee0946da28b"}},"169bdfc5f32541e7afe6c624d561af0d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"acb2b071aebb44449c792b9e8b2b36f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5ecd1f8e698c48088042b436513b6d32":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6714cd2a6ba6406ea041bee0946da28b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"66431cdef95447c5b35d708f203bfbf3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0e6b6b0418b84f69abc8d666010a2bdf","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7bb105fa161446b8952a8b92bd9e18ec","IPY_MODEL_48673b1ff05240208065279d020e1a00"]}},"0e6b6b0418b84f69abc8d666010a2bdf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7bb105fa161446b8952a8b92bd9e18ec":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_76e183ce2b4d45e688f95a5689520f32","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1961828,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1961828,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_645ab549a5ac44d1b487d3e39948e06f"}},"48673b1ff05240208065279d020e1a00":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f7b05da3f416402c9cdedbac5380176d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.96M/1.96M [00:00&lt;00:00, 4.91MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_510432ba09214a6fb7ad3470f449017a"}},"76e183ce2b4d45e688f95a5689520f32":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"645ab549a5ac44d1b487d3e39948e06f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f7b05da3f416402c9cdedbac5380176d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"510432ba09214a6fb7ad3470f449017a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c11ba0130def49c581856b6938aa47e8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_59b6532b879c43d0ae607e8d1c2f4428","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_fdb1d02c8579403f8d30d33307e5a05f","IPY_MODEL_1e247dff16a34e8f9d5861b282d61dee"]}},"59b6532b879c43d0ae607e8d1c2f4428":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fdb1d02c8579403f8d30d33307e5a05f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_aa1352f07a3741f49bebaa9905a625d4","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":625,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":625,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f29252fbf92e4c92914dbffd762fb4a3"}},"1e247dff16a34e8f9d5861b282d61dee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0b86c26e6e6a476f9f3c5567ee58db8b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 625/625 [00:00&lt;00:00, 1.03kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2f148ec3935443ad8a26aea3c6cc7471"}},"aa1352f07a3741f49bebaa9905a625d4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f29252fbf92e4c92914dbffd762fb4a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0b86c26e6e6a476f9f3c5567ee58db8b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2f148ec3935443ad8a26aea3c6cc7471":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b44294d26cef4f10a40020c0e25e39be":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e96b0626a00c4813a757748ef249d151","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5f6b4ef4b56c48c4b752a17b88d35b95","IPY_MODEL_3aebc40687ab41d1a68471d4feff4ff7"]}},"e96b0626a00c4813a757748ef249d151":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5f6b4ef4b56c48c4b752a17b88d35b95":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1d2d6850fa92465c9a2b2b50a0161c56","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1083389348,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1083389348,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_aab5891202ab4d89ad458c82184db397"}},"3aebc40687ab41d1a68471d4feff4ff7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d529592adece4e6bb3b09f27dcde99ce","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.08G/1.08G [00:20&lt;00:00, 53.0MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7d18e9727deb49cf9749710024cb2996"}},"1d2d6850fa92465c9a2b2b50a0161c56":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"aab5891202ab4d89ad458c82184db397":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d529592adece4e6bb3b09f27dcde99ce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7d18e9727deb49cf9749710024cb2996":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"f_4b2qRrnUWM"},"source":["<img src=\"https://www.ifsc.edu.br/image/layout_set_logo?img_id=1319584&t=1602803233260\" width=\"20%\">\n","\n","<center>\n","\n","---\n","# **Análise de Sentimento Multilíngue usando BERT**\n","## <u>Prof. Carlos Andres Ferrero</u>\n","## Instituto Federal de Santa Catarina (IFSC), Câmpus Lages\n","## Grupo de Pesquisa em Análise Inteligente de Dados (IDA-IFSC)\n","---\n","</center>"]},{"cell_type":"markdown","metadata":{"id":"Ck78ioofn0RT"},"source":["# Introdução\n","\n","**Objetivo**: introduzir o uso do modelo BERT para construir um modelo de classificação multilíngue para análise de sentimento de *reviews* de aplicativos.\n","\n","**Material e Método**: \n","\n","*Etapa 1 - Coleta de Dados:* os dados utilizados para contruir o modelo de classificação correspondem a avaliações de aplicativos, os quais foram extraídos utilizando webscrapping no site da Google Play Store. Cada avaliação possuia inicialmente um score de 1 a 5 e esses scores foram transformados em três classes ou labels: `postivo (score>3)`, `negativo (score<=3)`.\n","\n","*Etapa 2 - Pré-processamento de Dados:* o atributo classe foi codificado e as avaliações tokenizadas (transformação em *tokens*) usando BertTokenizer. Nesta etapa são apresentados e explicados alguns conceitos e parâmetros usados na tokenização.\n","\n","*Etapa 3 - Preparação dos Conjuntos de Dados:* o conjunto de dados com todas as avaliações é dividido em três conjuntos: treinamento, validação e teste.\n","\n","*Etapa 4 - Definição do Modelo de Classificação:* um modelo para classificação de sentenças baseado em BERT é apresentado, bem como uma função para transformar as instâncias do problema em entradas (`input`) e saídas (`output`) corretos para o treinamento do modelo em questão.\n","\n","*Etapa 5 - Treinamento do Modelo*: os conjuntos de dados treinamento e validação são utilizados para treinar o modelo, monitorar o treinamento e escolher o melhor modelo.\n","\n","*Etapa 6 - Avaliação do Modelo*: os conjunto de teste é utilizado para avaliar o modelo de classificação com dados não observados durante o treinamento ou o monitoramento do treinamento. O modelo foi avaliado utilizando medida de acurácia.\n","\n","**Escopo**:\n","\n","O escopo deste documento é limitado a estudar análise de sentimento por meio de classificação, usando um dos modelos do estado da arte em Processamento de Linguagem Natural (NLP) e abstrai os conceitos de WordEmbeddings, Sentence Embeddings e estruturas internas do modelo de Rede Neural para classificação: como Recurrent Neural Networks e Attention Layer."]},{"cell_type":"markdown","metadata":{"id":"N2ZEp4u22xSY"},"source":["# Desenvolvimento"]},{"cell_type":"markdown","metadata":{"id":"-mppS9Dv25TK"},"source":["Instalação e importação de bibliotecas."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"39AFIge9nvnO","executionInfo":{"status":"ok","timestamp":1624659735296,"user_tz":180,"elapsed":6384,"user":{"displayName":"Andrés Ferrero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy8GQ84pTpDGTyvPm8nJ1084hhRDHLTT7vapLIaQ=s64","userId":"08819764005078131707"}},"outputId":"5a3eb9ef-7abe-4a2f-90f8-ac62e0bbd056"},"source":["!pip install transformers"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/d5/c6c23ad75491467a9a84e526ef2364e523d45e2b0fae28a7cbe8689e7e84/transformers-4.8.1-py3-none-any.whl (2.5MB)\n","\u001b[K     |████████████████████████████████| 2.5MB 8.2MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 50.7MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 49.1MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n","Collecting huggingface-hub==0.0.12\n","  Downloading https://files.pythonhosted.org/packages/2f/ee/97e253668fda9b17e968b3f97b2f8e53aa0127e8807d24a547687423fe0b/huggingface_hub-0.0.12-py3-none-any.whl\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Installing collected packages: sacremoses, tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.8.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Osz6ZmGJ5Hpq","executionInfo":{"status":"ok","timestamp":1624659741384,"user_tz":180,"elapsed":6094,"user":{"displayName":"Andrés Ferrero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy8GQ84pTpDGTyvPm8nJ1084hhRDHLTT7vapLIaQ=s64","userId":"08819764005078131707"}}},"source":["# Basic\n","import csv\n","import pandas as pd\n","import numpy as np\n","import os\n","import re\n","\n","# Tensorflow\n","import tensorflow as tf\n","\n","# BERT\n","from transformers import BertTokenizer, BasicTokenizer\n","from transformers import TFBertModel, TFBertPreTrainedModel, TFBertForSequenceClassification, BertConfig\n","\n","# Scikit-leran\n","from sklearn.model_selection import train_test_split"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5_Q_Ij5_50Lk"},"source":["## Etapa 1 - Coleta de Dados"]},{"cell_type":"markdown","metadata":{"id":"q_qsmoJZ5u_3"},"source":["As avaliações utilizadas neste trabalho foram coletadas utilizando as bibliotecas `selenium` e `google-play-scrapper`. O script em `data/app_scrapping` coleta o Top 10 de aplicativos gratuítos e pagos da plataforma Google Play Store nos paises US e BR. Essa coleta resultou em 40 apps e, como alguns apps são repetidos, o número de aplicativos únicos foi 34. Desses aplicativos foram obtidas avaliações/*reviews* em inglês e português, até 600 avaliações de cada, até 300 com rating de 1 a 3 (negativo) e até 300 com rating de 4 a 5 (positivas). Essa coleta resultou em 66751 avaliações, as quais são apresentadas a seguir."]},{"cell_type":"code","metadata":{"id":"yZsj-KWL7OMj","colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"status":"ok","timestamp":1624659751001,"user_tz":180,"elapsed":235,"user":{"displayName":"Andrés Ferrero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy8GQ84pTpDGTyvPm8nJ1084hhRDHLTT7vapLIaQ=s64","userId":"08819764005078131707"}},"outputId":"b58be0c6-3f62-4107-b5e7-a5eef3015f70"},"source":["df = pd.read_csv('reviews.csv')\n","df"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>content</th>\n","      <th>score</th>\n","      <th>appId</th>\n","      <th>lang</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>I'm not giving 1 star because of the UI,I'm gi...</td>\n","      <td>1</td>\n","      <td>com.teamspeak.ts3client</td>\n","      <td>en</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Waste of money. Don't buy this. Disconnects wh...</td>\n","      <td>1</td>\n","      <td>com.teamspeak.ts3client</td>\n","      <td>en</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>UI nightmare: - dialogs with checked checkbox ...</td>\n","      <td>1</td>\n","      <td>com.teamspeak.ts3client</td>\n","      <td>en</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Super upset with how poorly this app performs ...</td>\n","      <td>1</td>\n","      <td>com.teamspeak.ts3client</td>\n","      <td>en</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>This app is rubbish pay for something that doe...</td>\n","      <td>1</td>\n","      <td>com.teamspeak.ts3client</td>\n","      <td>en</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>66747</th>\n","      <td>Sem dúvidas é o melhor launcher que tem, tanto...</td>\n","      <td>5</td>\n","      <td>com.teslacoilsw.launcher.prime</td>\n","      <td>pt</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>66748</th>\n","      <td>Ótimo</td>\n","      <td>5</td>\n","      <td>com.teslacoilsw.launcher.prime</td>\n","      <td>pt</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>66749</th>\n","      <td>Melhor launcher de todos, disparado. Vale cada...</td>\n","      <td>5</td>\n","      <td>com.teslacoilsw.launcher.prime</td>\n","      <td>pt</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>66750</th>\n","      <td>O MELHOR APP DO MUNDO!!</td>\n","      <td>5</td>\n","      <td>com.teslacoilsw.launcher.prime</td>\n","      <td>pt</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>66751</th>\n","      <td>Muito boa</td>\n","      <td>5</td>\n","      <td>com.teslacoilsw.launcher.prime</td>\n","      <td>pt</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>66752 rows × 5 columns</p>\n","</div>"],"text/plain":["                                                 content  score  ... lang     label\n","0      I'm not giving 1 star because of the UI,I'm gi...      1  ...   en  negative\n","1      Waste of money. Don't buy this. Disconnects wh...      1  ...   en  negative\n","2      UI nightmare: - dialogs with checked checkbox ...      1  ...   en  negative\n","3      Super upset with how poorly this app performs ...      1  ...   en  negative\n","4      This app is rubbish pay for something that doe...      1  ...   en  negative\n","...                                                  ...    ...  ...  ...       ...\n","66747  Sem dúvidas é o melhor launcher que tem, tanto...      5  ...   pt  positive\n","66748                                              Ótimo      5  ...   pt  positive\n","66749  Melhor launcher de todos, disparado. Vale cada...      5  ...   pt  positive\n","66750                            O MELHOR APP DO MUNDO!!      5  ...   pt  positive\n","66751                                          Muito boa      5  ...   pt  positive\n","\n","[66752 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":3}]},{"source":["Do total de avaliações, apenas 4 avaliações não tinham conetúdo algum."],"cell_type":"markdown","metadata":{}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"iOHrEaWpRHv3","executionInfo":{"status":"ok","timestamp":1624659765537,"user_tz":180,"elapsed":233,"user":{"displayName":"Andrés Ferrero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy8GQ84pTpDGTyvPm8nJ1084hhRDHLTT7vapLIaQ=s64","userId":"08819764005078131707"}},"outputId":"6622bb16-e41b-4199-f6f7-0988847f5913"},"source":["df['content'].isna().sum()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["4"]},"metadata":{"tags":[]},"execution_count":4}]},{"source":["Essas avaliações foram removidos do conjunto de dados, como segue."],"cell_type":"markdown","metadata":{}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"VPFjcRv9RRG1","executionInfo":{"status":"ok","timestamp":1624659802073,"user_tz":180,"elapsed":239,"user":{"displayName":"Andrés Ferrero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy8GQ84pTpDGTyvPm8nJ1084hhRDHLTT7vapLIaQ=s64","userId":"08819764005078131707"}},"outputId":"eadd4400-5aa4-468c-d007-096ded45d285"},"source":["df = df.dropna()\n","df"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>content</th>\n","      <th>score</th>\n","      <th>appId</th>\n","      <th>lang</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>I'm not giving 1 star because of the UI,I'm gi...</td>\n","      <td>1</td>\n","      <td>com.teamspeak.ts3client</td>\n","      <td>en</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Waste of money. Don't buy this. Disconnects wh...</td>\n","      <td>1</td>\n","      <td>com.teamspeak.ts3client</td>\n","      <td>en</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>UI nightmare: - dialogs with checked checkbox ...</td>\n","      <td>1</td>\n","      <td>com.teamspeak.ts3client</td>\n","      <td>en</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Super upset with how poorly this app performs ...</td>\n","      <td>1</td>\n","      <td>com.teamspeak.ts3client</td>\n","      <td>en</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>This app is rubbish pay for something that doe...</td>\n","      <td>1</td>\n","      <td>com.teamspeak.ts3client</td>\n","      <td>en</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>66747</th>\n","      <td>Sem dúvidas é o melhor launcher que tem, tanto...</td>\n","      <td>5</td>\n","      <td>com.teslacoilsw.launcher.prime</td>\n","      <td>pt</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>66748</th>\n","      <td>Ótimo</td>\n","      <td>5</td>\n","      <td>com.teslacoilsw.launcher.prime</td>\n","      <td>pt</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>66749</th>\n","      <td>Melhor launcher de todos, disparado. Vale cada...</td>\n","      <td>5</td>\n","      <td>com.teslacoilsw.launcher.prime</td>\n","      <td>pt</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>66750</th>\n","      <td>O MELHOR APP DO MUNDO!!</td>\n","      <td>5</td>\n","      <td>com.teslacoilsw.launcher.prime</td>\n","      <td>pt</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>66751</th>\n","      <td>Muito boa</td>\n","      <td>5</td>\n","      <td>com.teslacoilsw.launcher.prime</td>\n","      <td>pt</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>66748 rows × 5 columns</p>\n","</div>"],"text/plain":["                                                 content  score  ... lang     label\n","0      I'm not giving 1 star because of the UI,I'm gi...      1  ...   en  negative\n","1      Waste of money. Don't buy this. Disconnects wh...      1  ...   en  negative\n","2      UI nightmare: - dialogs with checked checkbox ...      1  ...   en  negative\n","3      Super upset with how poorly this app performs ...      1  ...   en  negative\n","4      This app is rubbish pay for something that doe...      1  ...   en  negative\n","...                                                  ...    ...  ...  ...       ...\n","66747  Sem dúvidas é o melhor launcher que tem, tanto...      5  ...   pt  positive\n","66748                                              Ótimo      5  ...   pt  positive\n","66749  Melhor launcher de todos, disparado. Vale cada...      5  ...   pt  positive\n","66750                            O MELHOR APP DO MUNDO!!      5  ...   pt  positive\n","66751                                          Muito boa      5  ...   pt  positive\n","\n","[66748 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"UXVu6HyN4-ID"},"source":["A seguir são apresentados o número de avaliações positivas e negativas, bem como a distribuição (em percentual) das instâncias do problema por classe."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"GTtoQrMg4-ID","executionInfo":{"status":"ok","timestamp":1624659887686,"user_tz":180,"elapsed":275,"user":{"displayName":"Andrés Ferrero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy8GQ84pTpDGTyvPm8nJ1084hhRDHLTT7vapLIaQ=s64","userId":"08819764005078131707"}},"outputId":"4e82a654-ca21-425b-df8e-a69ab9b7147e"},"source":["df.label.value_counts()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["positive    33773\n","negative    32975\n","Name: label, dtype: int64"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"DKboTaJL4-ID","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1624659888530,"user_tz":180,"elapsed":4,"user":{"displayName":"Andrés Ferrero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy8GQ84pTpDGTyvPm8nJ1084hhRDHLTT7vapLIaQ=s64","userId":"08819764005078131707"}},"outputId":"5262eac3-e04d-4216-9c67-b48e6380cfff"},"source":["df.label.value_counts(normalize=True).round(2)"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["positive    0.51\n","negative    0.49\n","Name: label, dtype: float64"]},"metadata":{"tags":[]},"execution_count":7}]},{"source":["A seguir são selecionadas as colunas de interesse `content` e `label`."],"cell_type":"markdown","metadata":{}},{"cell_type":"code","metadata":{"id":"oPexyDzlliuB","executionInfo":{"status":"ok","timestamp":1624659889495,"user_tz":180,"elapsed":5,"user":{"displayName":"Andrés Ferrero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy8GQ84pTpDGTyvPm8nJ1084hhRDHLTT7vapLIaQ=s64","userId":"08819764005078131707"}}},"source":["columns = ['content','label']\n","df = df[columns]"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jwTG29KC4-IF"},"source":["## Etapa 2 - Pré-processamento de Dados"]},{"cell_type":"markdown","metadata":{"id":"xt-A0VK04-IF"},"source":["Nesta etapa de pré-processamento inicialmente é realizada a codificação do atributo classe em um valor numérico, sendo `0` para negativo e `1` para positivo, bem a renomeação da coluna `content` para `text`."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":589},"id":"AOGRl4Y74-IG","executionInfo":{"status":"ok","timestamp":1624659891205,"user_tz":180,"elapsed":354,"user":{"displayName":"Andrés Ferrero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy8GQ84pTpDGTyvPm8nJ1084hhRDHLTT7vapLIaQ=s64","userId":"08819764005078131707"}},"outputId":"a0960b76-6297-401d-a63c-b5e3176ad29e"},"source":["to_replace = {\n","    'negative' : 0,    \n","    'positive' : 1    \n","}\n","\n","df['label'].replace(to_replace, inplace=True)\n","\n","to_rename = {\n","    'content' : 'text'\n","}\n","\n","df.rename(columns=to_rename, inplace=True)\n","\n","df"],"execution_count":9,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4582: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  method=method,\n","/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4308: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  errors=errors,\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>I'm not giving 1 star because of the UI,I'm gi...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Waste of money. Don't buy this. Disconnects wh...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>UI nightmare: - dialogs with checked checkbox ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Super upset with how poorly this app performs ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>This app is rubbish pay for something that doe...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>66747</th>\n","      <td>Sem dúvidas é o melhor launcher que tem, tanto...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>66748</th>\n","      <td>Ótimo</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>66749</th>\n","      <td>Melhor launcher de todos, disparado. Vale cada...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>66750</th>\n","      <td>O MELHOR APP DO MUNDO!!</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>66751</th>\n","      <td>Muito boa</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>66748 rows × 2 columns</p>\n","</div>"],"text/plain":["                                                    text  label\n","0      I'm not giving 1 star because of the UI,I'm gi...      0\n","1      Waste of money. Don't buy this. Disconnects wh...      0\n","2      UI nightmare: - dialogs with checked checkbox ...      0\n","3      Super upset with how poorly this app performs ...      0\n","4      This app is rubbish pay for something that doe...      0\n","...                                                  ...    ...\n","66747  Sem dúvidas é o melhor launcher que tem, tanto...      1\n","66748                                              Ótimo      1\n","66749  Melhor launcher de todos, disparado. Vale cada...      1\n","66750                            O MELHOR APP DO MUNDO!!      1\n","66751                                          Muito boa      1\n","\n","[66748 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"9OdP6ssT4-IG"},"source":["### Tokenização de Sentenças usando BertTokenizer\n","\n","A tokenização é um processo importante da análise de textos, pois permite separar um texto em unidades menores, mais facilmente representáveis por métodos e técnicas de analise de dados."]},{"cell_type":"code","metadata":{"id":"CaGA4AOb4-IG","colab":{"base_uri":"https://localhost:8080/","height":164,"referenced_widgets":["5cda119de6b44d7d9f390d352f93dd75","3b234d0112dd46ba91dcaae28e360fd8","7377fbb765ac4cdab2ae660cb21af4c0","873b64cdc5ca4d418fc0acdb69863bee","4fadff4913074fabb277dc307fe61788","73944a62dd8544bd8d91314f37378e74","ce1efceaf30e4d738e89564a0c0ac520","806698f0809e4f93be7c81edb50095a4","fd7652d730a141bf995493146d54a6ff","c9878fbbc01e43a089dd19c0e8b8454e","0d0b1b21a3ba402ca8386108fc942026","a76eefa6a3d5481e8989a1a249dff9dc","169bdfc5f32541e7afe6c624d561af0d","acb2b071aebb44449c792b9e8b2b36f0","5ecd1f8e698c48088042b436513b6d32","6714cd2a6ba6406ea041bee0946da28b","66431cdef95447c5b35d708f203bfbf3","0e6b6b0418b84f69abc8d666010a2bdf","7bb105fa161446b8952a8b92bd9e18ec","48673b1ff05240208065279d020e1a00","76e183ce2b4d45e688f95a5689520f32","645ab549a5ac44d1b487d3e39948e06f","f7b05da3f416402c9cdedbac5380176d","510432ba09214a6fb7ad3470f449017a"]},"executionInfo":{"status":"ok","timestamp":1624659902385,"user_tz":180,"elapsed":3550,"user":{"displayName":"Andrés Ferrero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy8GQ84pTpDGTyvPm8nJ1084hhRDHLTT7vapLIaQ=s64","userId":"08819764005078131707"}},"outputId":"84185af5-3875-486a-9a6c-e2e16f52333d"},"source":["PRETRAINED_MODEL = 'bert-base-multilingual-cased'\n","tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL, do_lower_case=False)"],"execution_count":10,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5cda119de6b44d7d9f390d352f93dd75","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fd7652d730a141bf995493146d54a6ff","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=29.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"66431cdef95447c5b35d708f203bfbf3","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1961828.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"source":["Um exemplo de aplicação da tokenização usando BertTokenizer multilíngue, segue abaixo"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"HEUJ_KWC4-IH","executionInfo":{"status":"ok","timestamp":1624659902386,"user_tz":180,"elapsed":16,"user":{"displayName":"Andrés Ferrero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy8GQ84pTpDGTyvPm8nJ1084hhRDHLTT7vapLIaQ=s64","userId":"08819764005078131707"}},"outputId":"89933d63-94ab-46fa-aebe-685f237f8167"},"source":["sentence = \"Not enjoying the app yet. Paid for full access for a year, and the WhatsApp feature isn't working properly\"\n","sentence"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"Not enjoying the app yet. Paid for full access for a year, and the WhatsApp feature isn't working properly\""]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"xP5Dp-8b4-IH","executionInfo":{"status":"ok","timestamp":1624659902386,"user_tz":180,"elapsed":12,"user":{"displayName":"Andrés Ferrero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy8GQ84pTpDGTyvPm8nJ1084hhRDHLTT7vapLIaQ=s64","userId":"08819764005078131707"}},"outputId":"fe0ff6ef-12a6-4a04-d9b2-3923892be973"},"source":["tokenized_sentence = tokenizer(sentence)\n","\n","for k, v in tokenized_sentence.items():\n","    print(k,v)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["input_ids [101, 16040, 84874, 10230, 10105, 72894, 21833, 119, 107353, 10162, 10142, 13375, 18314, 10142, 169, 10924, 117, 10111, 10105, 12489, 10107, 10738, 16587, 19072, 98370, 112, 188, 14616, 83438, 102]\n","token_type_ids [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","attention_mask [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jBOWRwbm4-IH"},"source":["O tokenizador BertTokenizer transforma cada sentença em três arrays de valores: `input_ids`, `token_type_ids` e `attention_mask`.\n","- `input_ids`: correspondem a índices de um dicionário (comumente denominado `vocab`) a que cada temo da sentença corresponde. Adicionalmente Bert adiciona alguns `ids` especiais, como de inicio e fim de sentença, bem como pontuações. Nesta versão do Bert, `bert-base-multilingual-cased`, temos um amplo vocabulário que inclui termos em mais de 100 idiomas e na forma case sensitive (palavras com maiúsculas ou minúsculas possuem `ids` diferentes).\n","- `token_type_ids`: em algumas aplicações Bert é utilizado em diálogos de pergunta resposta, como bots para conversa ou avaliação. No nosso estudo usamos apenas um sentença, portanto cada toke corresponde à mesma sentença.\n","- `attention_mask`: existem sentenças com poucos termos e outras com muitos termos. Em geral é necessário definir um tamanho máximo de termos para codificar e analisar, por exemplo os primeiros 10 tokens. Assim, sentenças com mais de 10 tokens são truncadas e, sentenças com menos, são preenchidas (`padding`) com `ids=0`. A informação de `attention_mask` indica quais `ids` devem ser considerados e quais não."]},{"cell_type":"markdown","metadata":{"id":"YZyn3lHa4-II"},"source":["No exemplo abaixo, realizamos utilizandos as opções de número máximo de tokens para 10, utilizando as opções de `truncation` e `padding`:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"bmvZdqAg4-II","executionInfo":{"status":"ok","timestamp":1624659904078,"user_tz":180,"elapsed":236,"user":{"displayName":"Andrés Ferrero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy8GQ84pTpDGTyvPm8nJ1084hhRDHLTT7vapLIaQ=s64","userId":"08819764005078131707"}},"outputId":"7dcfcfa2-6a68-4616-948b-46a0ff2c5b51"},"source":["sentences = [\"WhatsApp feature isn't working properly\",\"This is the best App\",\"Not so bad\"]\n","tokenized_sentences = tokenizer(sentences, max_length=10, padding=True, truncation=True)\n","\n","for k, v in tokenized_sentences.items():\n","    print(k,v)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["input_ids [[101, 12489, 10107, 10738, 16587, 19072, 98370, 112, 188, 102], [101, 10747, 10124, 10105, 12504, 73784, 102, 0, 0, 0], [101, 16040, 10380, 15838, 102, 0, 0, 0, 0, 0]]\n","token_type_ids [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n","attention_mask [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ROG4JRgJ4-II"},"source":["Decodificação das sentenças pelos seus `input_ids`:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"Vx7G7kcb4-II","executionInfo":{"status":"ok","timestamp":1624659905820,"user_tz":180,"elapsed":3,"user":{"displayName":"Andrés Ferrero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy8GQ84pTpDGTyvPm8nJ1084hhRDHLTT7vapLIaQ=s64","userId":"08819764005078131707"}},"outputId":"bc4b6dcc-746d-4f12-924b-c3e79d390bdd"},"source":["for i in range(len(sentences)):\n","    decoded = tokenizer.decode(tokenized_sentences['input_ids'][i])\n","    print(\"Original: {} | Decoded: {}\".format(sentences[i], decoded) )    "],"execution_count":14,"outputs":[{"output_type":"stream","text":["Original: WhatsApp feature isn't working properly | Decoded: [CLS] WhatsApp feature isn't [SEP]\n","Original: This is the best App | Decoded: [CLS] This is the best App [SEP] [PAD] [PAD] [PAD]\n","Original: Not so bad | Decoded: [CLS] Not so bad [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tCA9MBJS4-IJ"},"source":["Note que:\n","- Na sentença temos também token especiais que definem o inicio \\[CLS\\] e fim \\[SEP\\] da sentença, bem como de preenchimento \\[PAD\\].\n","- A primeira sentença foi truncada porque a trasformação em tokens resultou em mais do que o limite permitido de tokens.\n","- Nas sentenças 2 e 3 foi necessário realizar padding para preencher o espaço até 10 termos. Consequentmente os seus respectivos arrays `attention_mask` representam a informação de em quais tokens deve ter atenção e quais não.\n","As configurações de `max_length`, `padding` e `truncation`, são muito utilizadas no processo de tokenização de sentenças."]},{"cell_type":"markdown","metadata":{"id":"_81IjqWR4-IJ"},"source":["A seguir é apresentada uma função para codificar as nossas sentenças com configurações específicas, que será utilizada neste nosso trabalho."]},{"cell_type":"code","metadata":{"id":"PBmO2Q0Z4-IJ","executionInfo":{"status":"ok","timestamp":1624659908951,"user_tz":180,"elapsed":242,"user":{"displayName":"Andrés Ferrero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy8GQ84pTpDGTyvPm8nJ1084hhRDHLTT7vapLIaQ=s64","userId":"08819764005078131707"}}},"source":["def encode_sentences(X, tokenizer, max_length):\n","    return tokenizer.batch_encode_plus(X,\n","        max_length=max_length, # tamanho máximo da sequencia de tokens\n","        truncation=True, # truncar a sentença\n","        padding=True, # usar padding\n","        add_special_tokens=True, # adicionar tokens especiais [CLS] e [SEP]\n","        return_attention_mask=True, # Retornar attention_mask\n","        return_token_type_ids=False, # NÃO retornar token_type_ids, pois não são necessários        \n","        return_tensors='tf' # Formato para usar TensorFlow/Keras\n","        )"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8452hCsj4-IK"},"source":["Execução da função `encode_sentences` para as três primeiras sentenças do conjunto de dados"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"SPFlIuIV4-IK","executionInfo":{"status":"ok","timestamp":1624659910584,"user_tz":180,"elapsed":236,"user":{"displayName":"Andrés Ferrero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy8GQ84pTpDGTyvPm8nJ1084hhRDHLTT7vapLIaQ=s64","userId":"08819764005078131707"}},"outputId":"ad983b6b-2ab8-48fe-cdf4-938a18432908"},"source":["sentences = df.text[:3]\n","print(sentences)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["0    I'm not giving 1 star because of the UI,I'm gi...\n","1    Waste of money. Don't buy this. Disconnects wh...\n","2    UI nightmare: - dialogs with checked checkbox ...\n","Name: text, dtype: object\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"KcXP4Krp0RjN","executionInfo":{"status":"ok","timestamp":1624659916618,"user_tz":180,"elapsed":239,"user":{"displayName":"Andrés Ferrero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy8GQ84pTpDGTyvPm8nJ1084hhRDHLTT7vapLIaQ=s64","userId":"08819764005078131707"}},"outputId":"38310e06-21f3-4ee5-f113-19d2c4f70a64"},"source":["MAX_SEQUENCE_LENGTH = 64\n","encode_sentences(sentences, tokenizer, MAX_SEQUENCE_LENGTH )"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'input_ids': <tf.Tensor: shape=(3, 64), dtype=int32, numpy=\n","array([[   101,    146,    112,    181,  10472,  24426,    122,  16624,\n","         12373,  10108,  10105,    158,  11281,    117,    146,    112,\n","           181,  24426,    122,  16624,  10854,  10305,  10108,  11762,\n","         27874,  10107,    131,    122,    119,  10377,    112,    187,\n","        109513,  10376,  17920,  10105,  41008,  11674,  13246,  14884,\n","         12023,  10124,  13961,  10135,  11408,  22753,    119,    123,\n","           119,  11065,  10529,  10114,  19317,  20442,  12542,  38854,\n","           124,    119,  11065,  10529,  10114,  16868,    169,    102],\n","       [   101,  22034,  10216,  10108,  17920,    119,  11740,    112,\n","           188,  47715,  10531,    119,  42994,  15490,  39159,  10841,\n","           146,  31638,  10114,  12361,  10216,  16567,    119,    153,\n","         37026,    118,  10114,    118,  31311,  38199,  13663,  14884,\n","         15490,  17530,    119,  22319,  57026,  14722,  10708,  38854,\n","         21486,    117,  10380,  10189,    146,  10944,    112,    188,\n","         41541,  10106,  21486,    119,  51900,  25022,  10189,  45769,\n","         32992,  69196,  24951,  77261,    153,  12396,  30118,    102],\n","       [   101,    158,  11281,  16903,  34918,    131,    118,  10671,\n","         18007,  10107,  10169,  43662,  10336,  43662,  34078,    107,\n","         14794,  11897,  13123,    107,  11639, 102295,  34321,  85047,\n","           118,  11735,  10877,  10454,  69191,  40468,  64040,  38854,\n","        100529,  13416,  20924,  16903,  34918,    131,    118,  12976,\n","         10105,  10261,  11263,  10149,  13028,  17367,  18314,  10114,\n","         10435,  33646,    136,  11399,  10173,  74115,  10107,    136,\n","         12034,  10271,  10436,    136,  12689,  21256,  10271,    102]],\n","      dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(3, 64), dtype=int32, numpy=\n","array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n","       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n","      dtype=int32)>}"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"x2EaMjqc4-IK"},"source":["## Etapa 3 - Preparação dos Conjuntos de Dados"]},{"cell_type":"markdown","metadata":{"id":"tLx3WNn_0r6M"},"source":["A divisão do conjunto de dados para poder treinar, monitorar o treinamento do modelo, e avaliá-o com novos dados, é uma tarefa importante no processo de indução de qualquer modelo. Neste trabalho dividimos o conjunto de dados em treino, validação e teste.\n","\n","A seguir é apresentada a `train_val_test_split`, uma extensão de `train_test_split` com suporte a treino, validação e teste e, posteriormente uma explicação sobre o intuito de cada um desses três conjuntos."]},{"cell_type":"code","metadata":{"id":"CI5aumgE4-IL","executionInfo":{"status":"ok","timestamp":1624659921781,"user_tz":180,"elapsed":2,"user":{"displayName":"Andrés Ferrero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy8GQ84pTpDGTyvPm8nJ1084hhRDHLTT7vapLIaQ=s64","userId":"08819764005078131707"}}},"source":["from sklearn.model_selection import train_test_split\n","\n","def train_val_test_split(X, y, val_size = 0.25, test_size = 0.25, random_state = 42, shuffle = True, stratify = None ):    \n","    X_train, X_aux, y_train, y_aux = \\\n","        train_test_split(X, y, test_size = val_size + test_size, random_state=random_state, shuffle=shuffle, stratify=stratify)\n","    X_val, X_test, y_val, y_test = \\\n","        train_test_split(X_aux, y_aux, test_size = test_size / (val_size + test_size), random_state=random_state, shuffle=shuffle,stratify=y_aux if stratify is not None else None)\n","    return X_train, X_val, X_test, y_train, y_val, y_test"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"32xpwjeO4-IL"},"source":["A divisão do conjunto de dados em treino, validação e teste, ocorre da seguinte forma:\n","- `train` é usado para treinar o modelo de classificação\n","- `val` é usado como validação do modelo com novos durante o treinamento, a cada época. Isso permite monitorar o desempenho do algoritmo com novos dados, evitar possível overfitting, treinamento desnecessário e escolher um modelo com melhor desempenho para avaliação no futuro.\n","- `test` é usado, ao final, para avaliar o modelo escolhido com o conjunto de validação.\n","\n","Neste trabalho será utilizada uma distribuição de 33% para treino 33% para validação e 34% para teste."]},{"cell_type":"code","metadata":{"id":"Oa9pR_8-4-IL","executionInfo":{"status":"ok","timestamp":1624659944076,"user_tz":180,"elapsed":223,"user":{"displayName":"Andrés Ferrero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy8GQ84pTpDGTyvPm8nJ1084hhRDHLTT7vapLIaQ=s64","userId":"08819764005078131707"}}},"source":["from sklearn.model_selection import train_test_split\n","X = df['text']\n","y = df['label']\n","\n","val_size = 0.33\n","test_size = 0.34\n","X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(X, y, val_size=val_size, test_size=test_size, stratify=y)"],"execution_count":20,"outputs":[]},{"source":["Com os dados do conjunto de treinamento podemos estimar um valor adequado do parâmetro `MAX_SEQUENCE_LENGTH`, número máximo de tokens a serem considerado na análise. Neste estudo será considerado como MAX_SEQUENCE_LENGTH o valor que cobre 90\\% dos textos do dataset."],"cell_type":"markdown","metadata":{}},{"cell_type":"code","metadata":{"id":"DQJKgtVNASul","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1624659956509,"user_tz":180,"elapsed":11157,"user":{"displayName":"Andrés Ferrero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy8GQ84pTpDGTyvPm8nJ1084hhRDHLTT7vapLIaQ=s64","userId":"08819764005078131707"}},"outputId":"d975d25e-f693-43b0-ad7e-71b2d5479c88"},"source":["train_sentences_tokenized = tokenizer.batch_encode_plus(X_train)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (614 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"2_Ch6A6CB8j_","executionInfo":{"status":"ok","timestamp":1624659956511,"user_tz":180,"elapsed":23,"user":{"displayName":"Andrés Ferrero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy8GQ84pTpDGTyvPm8nJ1084hhRDHLTT7vapLIaQ=s64","userId":"08819764005078131707"}},"outputId":"d078259f-5ba7-4751-9af3-8f4dad81772d"},"source":["train_sentence_lengths = [ len(x) for x in train_sentences_tokenized['input_ids']]\n","print('90% das sentenças tem até {:.0f} tokens'.format( np.percentile(train_sentence_lengths, 90) ) )"],"execution_count":22,"outputs":[{"output_type":"stream","text":["90% das sentenças tem até 93 tokens\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"XnasJlaq6dl_","executionInfo":{"status":"ok","timestamp":1624659975610,"user_tz":180,"elapsed":236,"user":{"displayName":"Andrés Ferrero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy8GQ84pTpDGTyvPm8nJ1084hhRDHLTT7vapLIaQ=s64","userId":"08819764005078131707"}},"outputId":"c2c0b468-cd2d-41b1-e598-6a223dd2cbfb"},"source":["MAX_SEQUENCE_LENGTH = int( np.percentile(train_sentence_lengths, 90) )\n","MAX_SEQUENCE_LENGTH"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["93"]},"metadata":{"tags":[]},"execution_count":23}]},{"source":["Armazenamos o número de classes do problema para posterior utilização."],"cell_type":"markdown","metadata":{}},{"cell_type":"code","metadata":{"id":"6K0rut2lM90w","executionInfo":{"status":"ok","timestamp":1624659976642,"user_tz":180,"elapsed":3,"user":{"displayName":"Andrés Ferrero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy8GQ84pTpDGTyvPm8nJ1084hhRDHLTT7vapLIaQ=s64","userId":"08819764005078131707"}}},"source":["num_labels = len(y_train.unique()) # número de classes do problema"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"swsY3RcJ4-IM"},"source":["## Etapa 4 - Definição do Modelo de Classificação"]},{"cell_type":"markdown","metadata":{"id":"SzAJZ9gC4-IM"},"source":["Instanciamos o modelo BERT para classificação de sequências de tokens."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":421,"referenced_widgets":["c11ba0130def49c581856b6938aa47e8","59b6532b879c43d0ae607e8d1c2f4428","fdb1d02c8579403f8d30d33307e5a05f","1e247dff16a34e8f9d5861b282d61dee","aa1352f07a3741f49bebaa9905a625d4","f29252fbf92e4c92914dbffd762fb4a3","0b86c26e6e6a476f9f3c5567ee58db8b","2f148ec3935443ad8a26aea3c6cc7471","b44294d26cef4f10a40020c0e25e39be","e96b0626a00c4813a757748ef249d151","5f6b4ef4b56c48c4b752a17b88d35b95","3aebc40687ab41d1a68471d4feff4ff7","1d2d6850fa92465c9a2b2b50a0161c56","aab5891202ab4d89ad458c82184db397","d529592adece4e6bb3b09f27dcde99ce","7d18e9727deb49cf9749710024cb2996"]},"id":"FFSNocem4-IM","executionInfo":{"status":"ok","timestamp":1624660004797,"user_tz":180,"elapsed":25826,"user":{"displayName":"Andrés Ferrero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy8GQ84pTpDGTyvPm8nJ1084hhRDHLTT7vapLIaQ=s64","userId":"08819764005078131707"}},"outputId":"0b82a046-56fb-46c0-aa97-af0dbcf37acc"},"source":["model = TFBertForSequenceClassification.from_pretrained(PRETRAINED_MODEL, num_labels=num_labels, output_attentions=False, output_hidden_states=False)\n","model.summary()"],"execution_count":25,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c11ba0130def49c581856b6938aa47e8","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b44294d26cef4f10a40020c0e25e39be","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1083389348.0, style=ProgressStyle(descr…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n","\n","Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"tf_bert_for_sequence_classification\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","bert (TFBertMainLayer)       multiple                  177853440 \n","_________________________________________________________________\n","dropout_37 (Dropout)         multiple                  0         \n","_________________________________________________________________\n","classifier (Dense)           multiple                  1538      \n","=================================================================\n","Total params: 177,854,978\n","Trainable params: 177,854,978\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1Zt3_u9X4-IM"},"source":["O modelo de classificação BERT recebe como entrada um array com dois elementos. O primeiro elemento são os `input_ids` das sequências e o segundo elemento é a máscara de atenção (`attention_mask`) de cada sentença. \n","\n","Para facilitar o treainemtno do modelo definimos uma função que transforma valores de entrada e saída, X e y, para o formato esperado do modelo de classificação."]},{"cell_type":"code","metadata":{"id":"XJlQ1y3G4-IM","executionInfo":{"status":"ok","timestamp":1624660004798,"user_tz":180,"elapsed":6,"user":{"displayName":"Andrés Ferrero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy8GQ84pTpDGTyvPm8nJ1084hhRDHLTT7vapLIaQ=s64","userId":"08819764005078131707"}}},"source":["def transform_to_model_input(X, y):\n","    encoded_sentences = encode_sentences(X, tokenizer, MAX_SEQUENCE_LENGTH)\n","    X_ = [encoded_sentences['input_ids'], encoded_sentences['attention_mask']]\n","    y_ = tf.convert_to_tensor(y.values, dtype=tf.int16)    \n","    return X_, y_"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IrMJRDrr2WDM"},"source":["Abaixo é realizada a transformação dos dados de treinamento e validação para o formato adequado a ser usado pela função de treinamento."]},{"cell_type":"code","metadata":{"id":"MOJ6FNPh4-IN","executionInfo":{"status":"ok","timestamp":1624660029510,"user_tz":180,"elapsed":22353,"user":{"displayName":"Andrés Ferrero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy8GQ84pTpDGTyvPm8nJ1084hhRDHLTT7vapLIaQ=s64","userId":"08819764005078131707"}}},"source":["X_train_, y_train_ = transform_to_model_input(X_train, y_train)\n","X_val_  , y_val_  = transform_to_model_input(X_val  , y_val)"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HfLckI5I4-IN"},"source":["## Etapa 5 - Treinamento do Modelo"]},{"cell_type":"code","metadata":{"id":"WJqZNlZn4-IN","executionInfo":{"status":"ok","timestamp":1624660044772,"user_tz":180,"elapsed":223,"user":{"displayName":"Andrés Ferrero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy8GQ84pTpDGTyvPm8nJ1084hhRDHLTT7vapLIaQ=s64","userId":"08819764005078131707"}}},"source":["#optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5, epsilon=1e-08, clipnorm=1.0)\n","optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n","loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n","model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"TsumA9Ns4-IO","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1624660681600,"user_tz":180,"elapsed":634394,"user":{"displayName":"Andrés Ferrero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy8GQ84pTpDGTyvPm8nJ1084hhRDHLTT7vapLIaQ=s64","userId":"08819764005078131707"}},"outputId":"5f0c3445-6bb8-4230-b3b7-7924d91f9f16"},"source":["log_dir='tensorboard_data/tb_bert'\n","model_save_path='bert_model.h5'\n","\n","callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath=model_save_path,save_weights_only=True,monitor='val_loss',mode='min',save_best_only=True)]\n","\n","BATCH_SIZE = 32\n","history = []\n","history_ = model.fit(X_train_, y_train_, batch_size=BATCH_SIZE, epochs=1, validation_data=(X_val_,y_val_), callbacks=callbacks)\n","history.append(history_)"],"execution_count":30,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fb22f11fde0>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fb22f11fde0>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7fb24a9cadd0> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <function wrap at 0x7fb24a9cadd0> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n","Instructions for updating:\n","The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","689/689 [==============================] - ETA: 0s - loss: 0.5181 - accuracy: 0.7473WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","689/689 [==============================] - 631s 848ms/step - loss: 0.5181 - accuracy: 0.7473 - val_loss: 0.4640 - val_accuracy: 0.7856\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GlEkqI9w8Xtz","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1624661951964,"user_tz":180,"elapsed":1222209,"user":{"displayName":"Andrés Ferrero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy8GQ84pTpDGTyvPm8nJ1084hhRDHLTT7vapLIaQ=s64","userId":"08819764005078131707"}},"outputId":"41f9e176-2454-47ac-ea25-0873cb9acd50"},"source":["history_ = model.fit(X_train_, y_train_, batch_size=BATCH_SIZE, epochs=2, validation_data=(X_val_,y_val_), callbacks=callbacks)\n","history.append(history_)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["Epoch 1/2\n","689/689 [==============================] - 582s 846ms/step - loss: 0.4185 - accuracy: 0.8133 - val_loss: 0.4527 - val_accuracy: 0.8024\n","Epoch 2/2\n","689/689 [==============================] - 582s 845ms/step - loss: 0.3380 - accuracy: 0.8570 - val_loss: 0.4518 - val_accuracy: 0.8046\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Mtn54b8W6-v-"},"source":["## Etapa 6 - Avaliação do Modelo"]},{"cell_type":"code","metadata":{"id":"46POhKrK7_EL","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1624662540032,"user_tz":180,"elapsed":2424,"user":{"displayName":"Andrés Ferrero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy8GQ84pTpDGTyvPm8nJ1084hhRDHLTT7vapLIaQ=s64","userId":"08819764005078131707"}},"outputId":"a7fb51a8-442b-4cae-af01-0a85d88b9aee"},"source":["best_model = TFBertForSequenceClassification.from_pretrained(PRETRAINED_MODEL, num_labels=num_labels, output_attentions=False, output_hidden_states=False)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5, epsilon=1e-08, clipnorm=1.0)\n","loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n","best_model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n","\n","model_save_path='bert_model.h5'\n","best_model.load_weights(model_save_path)"],"execution_count":32,"outputs":[{"output_type":"stream","text":["All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n","\n","Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"s04id1o0_esS","executionInfo":{"status":"ok","timestamp":1624662552168,"user_tz":180,"elapsed":11791,"user":{"displayName":"Andrés Ferrero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy8GQ84pTpDGTyvPm8nJ1084hhRDHLTT7vapLIaQ=s64","userId":"08819764005078131707"}}},"source":["X_test_ , y_test_  = transform_to_model_input(X_test, y_test)"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"id":"GYQOYDf-Ci9W","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1624662756657,"user_tz":180,"elapsed":204492,"user":{"displayName":"Andrés Ferrero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy8GQ84pTpDGTyvPm8nJ1084hhRDHLTT7vapLIaQ=s64","userId":"08819764005078131707"}},"outputId":"6a7e8e53-b776-4918-9de5-b8c49bbe1824"},"source":["BATCH_SIZE=32\n","loss_test, acc_test = best_model.evaluate(X_test_, y_test_, batch_size=BATCH_SIZE)"],"execution_count":34,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","710/710 [==============================] - 150s 208ms/step - loss: 0.4590 - accuracy: 0.8030\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"z8F39KY18ssl","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1624662756662,"user_tz":180,"elapsed":13,"user":{"displayName":"Andrés Ferrero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggy8GQ84pTpDGTyvPm8nJ1084hhRDHLTT7vapLIaQ=s64","userId":"08819764005078131707"}},"outputId":"e3e288b5-99cb-4274-e7b0-b606bdccfc22"},"source":["print(\"acc_test:\", acc_test)"],"execution_count":35,"outputs":[{"output_type":"stream","text":["acc_test: 0.8030403256416321\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"upVoz9585Rgu"},"source":["# Considerações\n","\n","Neste estudo foi realizado o treinamento de um classificador baseado no modelo BERT multilingue. Foram utilizadas revisões dos aplicativos no Top 10 Gratuítos e Pagos nos Estados Unidos e no Brasil, tanto em idioma inglês quanto português. Os valores de acurácia do modelo construído para cada conjunto foram:\n","- Treino: 85.70%\n","- Validação: 80.46%\n","- Teste: 80.30%\n","\n","Além disso, foi realizada a captura de dados de revisões de aplicativos no Top 10 Gratuitos e Pagos na França, em françês. E foi alcançada uma acurácia semelhante à encontrada no conjunto de Teste, de 80%, o que sustenta a ideia de que a representação do modelo BERT multilíngue."]}]}