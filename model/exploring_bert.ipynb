{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exploring_bert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.9 64-bit ('env': venv)"
    },
    "interpreter": {
      "hash": "d8e8f2e5d0e66e453dd22f7a6e79a5e349fc9b089a0e75cf3c84597ed3ff7539"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bce5309eb2934e2dac3dd4b94a634ebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5782b72263784f7cbad8c2a1652b68cf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5e5f3550c05245f1981af2d9b0ffe74e",
              "IPY_MODEL_2e87a76951d146df9898fe8c57fe2edb"
            ]
          }
        },
        "5782b72263784f7cbad8c2a1652b68cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5e5f3550c05245f1981af2d9b0ffe74e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d218c9d55d7346d7a772714820a74bd3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 995526,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 995526,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3b94fedb0bc749eab83e590c27a025be"
          }
        },
        "2e87a76951d146df9898fe8c57fe2edb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6640306901bf498ba0b3fcce06cfac21",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 996k/996k [00:00&lt;00:00, 1.89MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f8a9044ba74d4d30bc5c006d0dc91935"
          }
        },
        "d218c9d55d7346d7a772714820a74bd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3b94fedb0bc749eab83e590c27a025be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6640306901bf498ba0b3fcce06cfac21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f8a9044ba74d4d30bc5c006d0dc91935": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "039e0935f5ba4761b69f7472a3a97206": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b6f6059ce5884448ba2b771fe1656ab9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_68d567f8c4d4447892b7f0742a901699",
              "IPY_MODEL_fe8518e393ef45a4ab022dc9bb1b0bba"
            ]
          }
        },
        "b6f6059ce5884448ba2b771fe1656ab9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "68d567f8c4d4447892b7f0742a901699": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3aeba3a011ff4f66a712182e9eb746ff",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 29,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e65b29eb0786451c9672ca6a29c19ece"
          }
        },
        "fe8518e393ef45a4ab022dc9bb1b0bba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_19e0f0f898e04607b6de89903c2914f1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29.0/29.0 [00:00&lt;00:00, 219B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6b6e9cf89bb64bacae826496e157d89e"
          }
        },
        "3aeba3a011ff4f66a712182e9eb746ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e65b29eb0786451c9672ca6a29c19ece": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "19e0f0f898e04607b6de89903c2914f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6b6e9cf89bb64bacae826496e157d89e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c422a999afe643b98cb8a4603198c318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_328151da66a747e5bf39e1b0dd21af4b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3ceffc4601624d63b9f9f9c0534ffc65",
              "IPY_MODEL_12fdbc1da3d440e98f00d11827abe9af"
            ]
          }
        },
        "328151da66a747e5bf39e1b0dd21af4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ceffc4601624d63b9f9f9c0534ffc65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5fc645ce62c442f1a7f3039765a5111c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1961828,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1961828,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_146928f53d5d4a2aaa31f4ba7cb9e9ff"
          }
        },
        "12fdbc1da3d440e98f00d11827abe9af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_43d28abaf17846b683e51e4427b6983a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.96M/1.96M [00:00&lt;00:00, 9.25MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_da494e18d4534f56966fe4ce4403c515"
          }
        },
        "5fc645ce62c442f1a7f3039765a5111c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "146928f53d5d4a2aaa31f4ba7cb9e9ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "43d28abaf17846b683e51e4427b6983a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "da494e18d4534f56966fe4ce4403c515": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a03d101dfe494e00ba112d7ea4e3a573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cddb5cfe4e0a4469a80e502e5b3df176",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_508ffab622ec4f74baafdccfdb49e4b0",
              "IPY_MODEL_925abebb0e7446c5a2d774b4336d27db"
            ]
          }
        },
        "cddb5cfe4e0a4469a80e502e5b3df176": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "508ffab622ec4f74baafdccfdb49e4b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_619e9ab3d2bf4c69ae1fb64abe28ff5b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 625,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 625,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0d8eb572f19343c18ad39b468c50061b"
          }
        },
        "925abebb0e7446c5a2d774b4336d27db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_acfeb13ae6424e32990249f09558e8b7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 625/625 [00:22&lt;00:00, 28.2B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_01f739b862fb48bc97fa347c28953168"
          }
        },
        "619e9ab3d2bf4c69ae1fb64abe28ff5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0d8eb572f19343c18ad39b468c50061b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "acfeb13ae6424e32990249f09558e8b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "01f739b862fb48bc97fa347c28953168": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3781a1a017c84c28b459a36d4422590e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1352d307972e4df9875dc117c9f75150",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e87ab2b7c0274ae488beb327d2927089",
              "IPY_MODEL_c1b45c3ac07c434aa2a58664d53b8d55"
            ]
          }
        },
        "1352d307972e4df9875dc117c9f75150": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e87ab2b7c0274ae488beb327d2927089": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b1be5c6abf3f412298dddc39cbca1d13",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1083389348,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1083389348,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c30af01b52f40c0bffd9f409bfe2032"
          }
        },
        "c1b45c3ac07c434aa2a58664d53b8d55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_80b1555d089c4f59811aab0d43dbf4f5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.08G/1.08G [00:21&lt;00:00, 49.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a8f39850f903477489c5ca0931658392"
          }
        },
        "b1be5c6abf3f412298dddc39cbca1d13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c30af01b52f40c0bffd9f409bfe2032": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "80b1555d089c4f59811aab0d43dbf4f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a8f39850f903477489c5ca0931658392": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_4b2qRrnUWM"
      },
      "source": [
        "<img src=\"https://www.ifsc.edu.br/image/layout_set_logo?img_id=1319584&t=1602803233260\" width=\"20%\">\n",
        "\n",
        "<center>\n",
        "\n",
        "---\n",
        "# **Análise de Sentimento Multilíngue usando BERT**\n",
        "## <u>Prof. Carlos Andres Ferrero</u>\n",
        "## Instituto Federal de Santa Catarina (IFSC), Câmpus Lages\n",
        "## Grupo de Pesquisa em Análise Inteligente de Dados (IDA-IFSC)\n",
        "---\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck78ioofn0RT"
      },
      "source": [
        "# Introdução\n",
        "\n",
        "**Objetivo**: introduzir o uso do modelo BERT para construir um modelo de classificação multilíngue para análise de sentimento de *reviews* de aplicativos.\n",
        "\n",
        "**Material e Método**: \n",
        "\n",
        "*Etapa 1 - Coleta de Dados:* os dados utilizados para contruir o modelo de classificação correspondem a avaliações de aplicativos, os quais foram extraídos utilizando webscrapping no site da Google Play Store. Cada avaliação possuia inicialmente um score de 1 a 5 e esses scores foram transformados em três classes ou labels: `postivo (score>=3)`, `negativo (score<3)`.\n",
        "\n",
        "*Etapa 2 - Pré-processamento de Dados:* o atributo classe foi codificado e as avaliações tokenizadas (transformação em *tokens*) usando BertTokenizer. Nesta etapa são apresentados e explicados alguns conceitos e parâmetros usados na tokenização.\n",
        "\n",
        "*Etapa 3 - Preparação dos Conjuntos de Dados:* o conjunto de dados com todas as avaliações é dividido em três conjuntos: treinamento, validação e teste.\n",
        "\n",
        "*Etapa 4 - Definição do Modelo de Classificação:* um modelo para classificação de sentenças baseado em BERT é apresentado, bem como uma função para transformar as instâncias do problema em entradas (`input`) e saídas (`output`) corretos para o treinamento do modelo em questão.\n",
        "\n",
        "*Etapa 5 - Treinamento do Modelo*: os conjuntos de dados treinamento e validação são utilizados para treinar o modelo, monitorar o treinamento e escolher o melhor modelo.\n",
        "\n",
        "*Etapa 6 - Avaliação do Modelo*: os conjunto de teste é utilizado para avaliar o modelo de classificação com dados não observados durante o treinamento ou o monitoramento do treinamento. O modelo foi avaliado utilizando medida de acurácia.\n",
        "\n",
        "**Escopo**:\n",
        "\n",
        "O escopo deste documento é limitado a estudar análise de sentimento por meio de classificação, usando um dos modelos do estado da arte em Processamento de Linguagem Natural (NLP) e abstrai os conceitos de WordEmbeddings, Sentence Embeddings e estruturas internas do modelo de Rede Neural para classificação: como Recurrent Neural Networks e Attention Layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2ZEp4u22xSY"
      },
      "source": [
        "# Desenvolvimento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mppS9Dv25TK"
      },
      "source": [
        "Instalação e importação de bibliotecas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39AFIge9nvnO",
        "outputId": "a591fe1e-65e4-42d0-9ede-b905ae334145"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\andres\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (4.8.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\andres\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in c:\\users\\andres\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in c:\\users\\andres\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\andres\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (4.61.1)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\andres\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\andres\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in c:\\users\\andres\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\andres\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (2021.4.4)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-gpu (c:\\users\\andres\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-cpu (c:\\users\\andres\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-gpu (c:\\users\\andres\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-cpu (c:\\users\\andres\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-gpu (c:\\users\\andres\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-cpu (c:\\users\\andres\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-gpu (c:\\users\\andres\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-cpu (c:\\users\\andres\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-gpu (c:\\users\\andres\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -ensorflow-cpu (c:\\users\\andres\\appdata\\local\\programs\\python\\python38\\lib\\site-packages)\n",
            "Requirement already satisfied: requests in c:\\users\\andres\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\andres\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\andres\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\andres\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\andres\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\andres\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\andres\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\andres\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: six in c:\\users\\andres\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in c:\\users\\andres\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sacremoses->transformers) (8.0.0)\n",
            "Requirement already satisfied: joblib in c:\\users\\andres\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\andres\\appdata\\roaming\\python\\python38\\site-packages (from click->sacremoses->transformers) (0.4.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Osz6ZmGJ5Hpq"
      },
      "source": [
        "# Basic\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "\n",
        "# Tensorflow\n",
        "import tensorflow as tf\n",
        "\n",
        "# BERT\n",
        "from transformers import BertTokenizer, BasicTokenizer\n",
        "from transformers import TFBertModel, TFBertPreTrainedModel, TFBertForSequenceClassification, BertConfig\n",
        "\n",
        "# Scikit-leran\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_Q_Ij5_50Lk"
      },
      "source": [
        "## Etapa 1 - Coleta de Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_qsmoJZ5u_3"
      },
      "source": [
        "Carregando os dois conjuntos de dados de avaliações em inlgês e português."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZsj-KWL7OMj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "ff10aa30-a71b-4ecb-e7a7-aa7f9d81224a"
      },
      "source": [
        "df_en = pd.read_csv('../data/app_reviews_en_processed.csv')\n",
        "df_pt = pd.read_csv('../data/app_reviews_pt_processed.csv')\n",
        "df = pd.concat([df_en,df_pt], ignore_index=True).dropna()\n",
        "df"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text     label  score\n",
              "0      Not enjoying the app yet.. Paid for full acces...  negative      1\n",
              "1      This app implied that it had better integratio...  negative      1\n",
              "2      The trial period is too short to really know i...  negative      1\n",
              "3      I've used this before and dumped it, and I gav...  negative      1\n",
              "4      Used to be great, am now stuck with this bug t...  negative      1\n",
              "...                                                  ...       ...    ...\n",
              "28306                                          Muito bom  positive      5\n",
              "28307  Bastante funcional, reune em um só app varias ...  positive      5\n",
              "28308                        Melhor aplicativo da linha!  positive      5\n",
              "28309                                         Muito util  positive      5\n",
              "28310                     Muito prático, gostei bastante  positive      5\n",
              "\n",
              "[28310 rows x 3 columns]"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Not enjoying the app yet.. Paid for full acces...</td>\n      <td>negative</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This app implied that it had better integratio...</td>\n      <td>negative</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The trial period is too short to really know i...</td>\n      <td>negative</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I've used this before and dumped it, and I gav...</td>\n      <td>negative</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Used to be great, am now stuck with this bug t...</td>\n      <td>negative</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>28306</th>\n      <td>Muito bom</td>\n      <td>positive</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>28307</th>\n      <td>Bastante funcional, reune em um só app varias ...</td>\n      <td>positive</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>28308</th>\n      <td>Melhor aplicativo da linha!</td>\n      <td>positive</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>28309</th>\n      <td>Muito util</td>\n      <td>positive</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>28310</th>\n      <td>Muito prático, gostei bastante</td>\n      <td>positive</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>28310 rows × 3 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXVu6HyN4-ID"
      },
      "source": [
        "Selecionar avaliações positivas e negativas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTtoQrMg4-ID",
        "outputId": "a1764ee9-a9fa-4e4c-8a23-073f361e3113"
      },
      "source": [
        "df.label.value_counts()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "positive    19456\n",
              "negative     8854\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKboTaJL4-ID",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "237b41e4-16df-42fb-a230-cf5ebfff4485"
      },
      "source": [
        "df.label.value_counts(normalize=True).round(2)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "positive    0.69\n",
              "negative    0.31\n",
              "Name: label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPexyDzlliuB"
      },
      "source": [
        "columns = ['text','label']\n",
        "df = df[columns] "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwTG29KC4-IF"
      },
      "source": [
        "## Etapa 2 - Pré-processamento de Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xt-A0VK04-IF"
      },
      "source": [
        "### Codificação do atributo classe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "AOGRl4Y74-IG",
        "outputId": "f5545061-0044-45a1-fe5d-37de9ad34d25"
      },
      "source": [
        "to_replace = {\n",
        "    'negative' : 0,    \n",
        "    'positive' : 1    \n",
        "}\n",
        "\n",
        "df['label'].replace(to_replace, inplace=True)\n",
        "\n",
        "df"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "d:\\Users\\andres\\git_projects\\multi-language-sentiment-analysis\\env\\lib\\site-packages\\pandas\\core\\series.py:4509: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  return super().replace(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text  label\n",
              "0      Not enjoying the app yet.. Paid for full acces...      0\n",
              "1      This app implied that it had better integratio...      0\n",
              "2      The trial period is too short to really know i...      0\n",
              "3      I've used this before and dumped it, and I gav...      0\n",
              "4      Used to be great, am now stuck with this bug t...      0\n",
              "...                                                  ...    ...\n",
              "28306                                          Muito bom      1\n",
              "28307  Bastante funcional, reune em um só app varias ...      1\n",
              "28308                        Melhor aplicativo da linha!      1\n",
              "28309                                         Muito util      1\n",
              "28310                     Muito prático, gostei bastante      1\n",
              "\n",
              "[28310 rows x 2 columns]"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Not enjoying the app yet.. Paid for full acces...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>This app implied that it had better integratio...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>The trial period is too short to really know i...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I've used this before and dumped it, and I gav...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Used to be great, am now stuck with this bug t...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>28306</th>\n      <td>Muito bom</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>28307</th>\n      <td>Bastante funcional, reune em um só app varias ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>28308</th>\n      <td>Melhor aplicativo da linha!</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>28309</th>\n      <td>Muito util</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>28310</th>\n      <td>Muito prático, gostei bastante</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>28310 rows × 2 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OdP6ssT4-IG"
      },
      "source": [
        "### Tokenização de Sentenças usando BertTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaGA4AOb4-IG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "bce5309eb2934e2dac3dd4b94a634ebd",
            "5782b72263784f7cbad8c2a1652b68cf",
            "5e5f3550c05245f1981af2d9b0ffe74e",
            "2e87a76951d146df9898fe8c57fe2edb",
            "d218c9d55d7346d7a772714820a74bd3",
            "3b94fedb0bc749eab83e590c27a025be",
            "6640306901bf498ba0b3fcce06cfac21",
            "f8a9044ba74d4d30bc5c006d0dc91935",
            "039e0935f5ba4761b69f7472a3a97206",
            "b6f6059ce5884448ba2b771fe1656ab9",
            "68d567f8c4d4447892b7f0742a901699",
            "fe8518e393ef45a4ab022dc9bb1b0bba",
            "3aeba3a011ff4f66a712182e9eb746ff",
            "e65b29eb0786451c9672ca6a29c19ece",
            "19e0f0f898e04607b6de89903c2914f1",
            "6b6e9cf89bb64bacae826496e157d89e",
            "c422a999afe643b98cb8a4603198c318",
            "328151da66a747e5bf39e1b0dd21af4b",
            "3ceffc4601624d63b9f9f9c0534ffc65",
            "12fdbc1da3d440e98f00d11827abe9af",
            "5fc645ce62c442f1a7f3039765a5111c",
            "146928f53d5d4a2aaa31f4ba7cb9e9ff",
            "43d28abaf17846b683e51e4427b6983a",
            "da494e18d4534f56966fe4ce4403c515"
          ]
        },
        "outputId": "0fc72545-2cde-41a0-beec-66c484743b11"
      },
      "source": [
        "PRETRAINED_MODEL = 'bert-base-multilingual-cased'\n",
        "tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL, do_lower_case=False)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HEUJ_KWC4-IH",
        "outputId": "08540d39-29c2-46d2-c802-e1e5f6b87742"
      },
      "source": [
        "sentence = \"Not enjoying the app yet. Paid for full access for a year, and the WhatsApp feature isn't working properly\"\n",
        "sentence"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Not enjoying the app yet. Paid for full access for a year, and the WhatsApp feature isn't working properly\""
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xP5Dp-8b4-IH",
        "outputId": "17d1dd1a-54e6-43dd-f282-6bd2f9dfa72f"
      },
      "source": [
        "tokenized_sentence = tokenizer(sentence)\n",
        "\n",
        "for k, v in tokenized_sentence.items():\n",
        "    print(k,v)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids [101, 16040, 84874, 10230, 10105, 72894, 21833, 119, 107353, 10162, 10142, 13375, 18314, 10142, 169, 10924, 117, 10111, 10105, 12489, 10107, 10738, 16587, 19072, 98370, 112, 188, 14616, 83438, 102]\ntoken_type_ids [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\nattention_mask [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBOWRwbm4-IH"
      },
      "source": [
        "O tokenizador BertTokenizer transforma cada sentença em três arrays de valores: `input_ids`, `token_type_ids` e `attention_mask`.\n",
        "- `input_ids`: correspondem a índices de um dicionário (comumente denominado `vocab`) a que cada temo da sentença corresponde. Adicionalmente Bert adiciona alguns `ids` especiais, como de inicio e fim de sentença, bem como pontuações. Nesta versão do Bert, `bert-base-multilingual-cased`, temos um amplo vocabulário que inclui termos em mais de 100 idiomas e na forma case sensitive (palavras com maiúsculas ou minúsculas possuem `ids` diferentes).\n",
        "- `token_type_ids`: em algumas aplicações Bert é utilizado em diálogos de pergunta resposta, como bots para conversa ou avaliação. No nosso estudo usamos apenas um sentença, portanto cada toke corresponde à mesma sentença.\n",
        "- `attention_mask`: existem sentenças com poucos termos e outras com muitos termos. Em geral é necessário definir um tamanho máximo de termos para codificar e analisar, por exemplo os primeiros 10 tokens. Assim, sentenças com mais de 10 tokens são truncadas e, sentenças com menos, são preenchidas (`padding`) com `ids=0`. A informação de `attention_mask` indica quais `ids` devem ser considerados e quais não."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZyn3lHa4-II"
      },
      "source": [
        "No exemplo abaixo, realizamos utilizandos as opções de número máximo de tokens para 10, utilizando as opções de `truncation` e `padding`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmvZdqAg4-II",
        "outputId": "6ee99d03-ae25-40a5-e90d-1b5eeafb8522"
      },
      "source": [
        "sentences = [\"WhatsApp feature isn't working properly\",\"This is the best App\",\"Not so bad\"]\n",
        "tokenized_sentences = tokenizer(sentences, max_length=10, padding=True, truncation=True)\n",
        "\n",
        "for k, v in tokenized_sentences.items():\n",
        "    print(k,v)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids [[101, 12489, 10107, 10738, 16587, 19072, 98370, 112, 188, 102], [101, 10747, 10124, 10105, 12504, 73784, 102, 0, 0, 0], [101, 16040, 10380, 15838, 102, 0, 0, 0, 0, 0]]\ntoken_type_ids [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\nattention_mask [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 0, 0, 0, 0, 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROG4JRgJ4-II"
      },
      "source": [
        "Decodificando as sentenças pelos seus `input_ids`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vx7G7kcb4-II",
        "outputId": "e8aaa6de-fa65-4e06-81a0-735533c6a173"
      },
      "source": [
        "for i in range(len(sentences)):\n",
        "    decoded = tokenizer.decode(tokenized_sentences['input_ids'][i])\n",
        "    print(\"Original: {} | Decoded: {}\".format(sentences[i], decoded) )    "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: WhatsApp feature isn't working properly | Decoded: [CLS] WhatsApp feature isn't [SEP]\nOriginal: This is the best App | Decoded: [CLS] This is the best App [SEP] [PAD] [PAD] [PAD]\nOriginal: Not so bad | Decoded: [CLS] Not so bad [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCA9MBJS4-IJ"
      },
      "source": [
        "Note que:\n",
        "- Na sentença temos também token especiais que definem o inicio \\[CLS\\] e fim \\[SEP\\] da sentença, bem como de preenchimento \\[PAD\\].\n",
        "- A primeira sentença foi truncada porque a trasformação em tokens resultou em mais do que o limite permitido de tokens.\n",
        "- Nas sentenças 2 e 3 foi necessário realizar padding para preencher o espaço até 10 termos. Consequentmente os seus respectivos arrays `attention_mask` representam a informação de em quais tokens deve ter atenção e quais não.\n",
        "As configurações de `max_length`, `padding` e `truncation`, são muito utilizadas no processo de tokenização de sentenças."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_81IjqWR4-IJ"
      },
      "source": [
        "A seguir é apresentada uma função para codificar as nossas sentenças com configurações específicas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBmO2Q0Z4-IJ"
      },
      "source": [
        "def encode_sentences(X, tokenizer, max_length):\n",
        "    return tokenizer.batch_encode_plus(X,\n",
        "        max_length=max_length, # tamanho máximo da sequencia de tokens\n",
        "        truncation=True, # truncar a sentença\n",
        "        padding=True, # usar padding\n",
        "        add_special_tokens=True, # adicionar tokens especiais [CLS] e [SEP]\n",
        "        return_attention_mask=True, # Retornar attention_mask\n",
        "        return_token_type_ids=False, # NÃO retornar token_type_ids, pois não são necessários        \n",
        "        return_tensors='tf' # Formato para usar TensorFlow/Keras\n",
        "        )"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8452hCsj4-IK"
      },
      "source": [
        "Execução da função `encode_sentences` para as três primeiras sentenças "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPFlIuIV4-IK",
        "outputId": "a89bf70c-6c24-425d-9c02-f271d0d00b3e"
      },
      "source": [
        "sentences = df.text[:3]\n",
        "print(sentences)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    Not enjoying the app yet.. Paid for full acces...\n1    This app implied that it had better integratio...\n2    The trial period is too short to really know i...\nName: text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcXP4Krp0RjN",
        "outputId": "757d0ee7-e31f-41ed-e863-01cfc0d79982"
      },
      "source": [
        "MAX_SEQUENCE_LENGTH = 64\n",
        "encode_sentences(sentences, tokenizer, MAX_SEQUENCE_LENGTH )"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': <tf.Tensor: shape=(3, 64), dtype=int32, numpy=\n",
              "array([[   101,  16040,  84874,  10230,  10105,  72894,  21833,    119,\n",
              "           119, 107353,  10162,  10142,  13375,  18314,  10142,    169,\n",
              "         10924,    117,  10111,  10105,  12489,  10107,  10738,  16587,\n",
              "         19072,  98370,    112,    188,  14616,  83438,    117,  27156,\n",
              "         29421,    169,  11639,  14956,  11304,  10142,  30767,    117,\n",
              "         21001,  13383,  12014,  22807,  11639,  14956,  11304,  10374,\n",
              "         10590,  11847,  10142,  24848,    119,  10747,  10124,  10472,\n",
              "         10105,  10422,  34469,    119,  10747,  14819,  10347,    102],\n",
              "       [   101,  10747,  72894,  10211, 104309,  10189,  10271,  10374,\n",
              "         18322,  64861,  10169,  41181,  20999,  11084,  10271,  10106,\n",
              "         18638,  15107,    119,  10576,  17895,    117,  10271,  10124,\n",
              "           169,  14772,  11989,    117,  13800,    118,  10105,  23582,\n",
              "         10108,  11178,  23599,  10114,  11847,  11639,  14956,  25779,\n",
              "         13382,  41181,  20999,  17574,  10189,  13877,  10108,  10105,\n",
              "         72894,  10124,    169,  59158,  10108,  17920,    117,  12277,\n",
              "         10189,  10124,  20442,  12126,  13170,  10108,  14616,    102],\n",
              "       [   101,  10117,  23626,  13127,  10124,  16683,  13716,  10114,\n",
              "         30181,  21852,  12277,  10271,    112,    187,  55668,    119,\n",
              "           146,    112,  10323,  25938,  10142,  93244,  10147,  10111,\n",
              "         10893,  11823,  10105,  12998,  38819,  10124,    169,  11339,\n",
              "         17954,  10107,    119,  10117,  12998,  72894,  10472,  18162,\n",
              "         10114,  96935,  61637,    117,  10472,  39429,  19181,  43941,\n",
              "           119,  25220,  10454,  10472,  27675,  10142,  10105,  29115,\n",
              "         12277,  13028,  10301,  34279,  10114,  11760,  10135,    102]])>, 'attention_mask': <tf.Tensor: shape=(3, 64), dtype=int32, numpy=\n",
              "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "       [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])>}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2EaMjqc4-IK"
      },
      "source": [
        "## Etapa 3 - Preparação dos Conjuntos de Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLx3WNn_0r6M"
      },
      "source": [
        "A função `train_val_test_split` abaixo é uma extensão de `train_test_split` com suporte a treino, validação e teste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CI5aumgE4-IL"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def train_val_test_split(X, y, val_size = 0.25, test_size = 0.25, random_state = 42, shuffle = True, stratify = None ):    \n",
        "    X_train, X_aux, y_train, y_aux = \\\n",
        "        train_test_split(X, y, test_size = val_size + test_size, random_state=random_state, shuffle=shuffle, stratify=stratify)\n",
        "    X_val, X_test, y_val, y_test = \\\n",
        "        train_test_split(X_aux, y_aux, test_size = test_size / (val_size + test_size), random_state=random_state, shuffle=shuffle,stratify=y_aux if stratify is not None else None)\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32xpwjeO4-IL"
      },
      "source": [
        "A divisão do conjunto de dados em treino, validação e teste, ocorre da seguinte forma:\n",
        "- `train` é usado para treinar o modelo de classificação\n",
        "- `val` é usado como validação do modelo com novos durante o treinamento, a cada época. Isso permite monitorar o desempenho do algoritmo com novos dados, evitar possível overfitting, treinamento desnecessário e escolher um modelo com melhor desempenho para avaliação no futuro.\n",
        "- `test` é usado, ao final, para avaliar o modelo escolhido com o conjunto de validação.\n",
        "\n",
        "Neste trabalho será utilizada uma distribuição de 20\\% para treino 40\\% para validação e 40\\% para teste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oa9pR_8-4-IL"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = df['text']\n",
        "y = df['label']\n",
        "\n",
        "val_size = 0.25\n",
        "test_size = 0.25\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(X, y, val_size=val_size, test_size=test_size, stratify=y)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQJKgtVNASul",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "175558f8-dde3-4cc4-e563-d7e6fdbece33"
      },
      "source": [
        "train_sentences_tokenized = tokenizer.batch_encode_plus(X_train)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (570 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_Ch6A6CB8j_",
        "outputId": "e94627d0-bf14-45fd-f85b-e233ed8f9b7f"
      },
      "source": [
        "train_sentence_lengths = [ len(x) for x in train_sentences_tokenized['input_ids']]\n",
        "print('90% das sentenças tem até {:.0f} tokens'.format( np.percentile(train_sentence_lengths, 90) ) )"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90% das sentenças tem até 102 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnasJlaq6dl_",
        "outputId": "05ff969f-807c-4766-e86b-c113fe820bf2"
      },
      "source": [
        "MAX_SEQUENCE_LENGTH = int( np.percentile(train_sentence_lengths, 90) )\n",
        "MAX_SEQUENCE_LENGTH"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "102"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6K0rut2lM90w"
      },
      "source": [
        "num_labels = len(y_train.unique()) # número de classes do problema"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swsY3RcJ4-IM"
      },
      "source": [
        "## Etapa 4 - Definição do Modelo de Classificação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzAJZ9gC4-IM"
      },
      "source": [
        "Instanciamos o modelo BERT para classificação de sequências de tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421,
          "referenced_widgets": [
            "a03d101dfe494e00ba112d7ea4e3a573",
            "cddb5cfe4e0a4469a80e502e5b3df176",
            "508ffab622ec4f74baafdccfdb49e4b0",
            "925abebb0e7446c5a2d774b4336d27db",
            "619e9ab3d2bf4c69ae1fb64abe28ff5b",
            "0d8eb572f19343c18ad39b468c50061b",
            "acfeb13ae6424e32990249f09558e8b7",
            "01f739b862fb48bc97fa347c28953168",
            "3781a1a017c84c28b459a36d4422590e",
            "1352d307972e4df9875dc117c9f75150",
            "e87ab2b7c0274ae488beb327d2927089",
            "c1b45c3ac07c434aa2a58664d53b8d55",
            "b1be5c6abf3f412298dddc39cbca1d13",
            "2c30af01b52f40c0bffd9f409bfe2032",
            "80b1555d089c4f59811aab0d43dbf4f5",
            "a8f39850f903477489c5ca0931658392"
          ]
        },
        "id": "FFSNocem4-IM",
        "outputId": "232c82b5-3aa9-4a3a-b142-7bb922656aa9"
      },
      "source": [
        "model = TFBertForSequenceClassification.from_pretrained(PRETRAINED_MODEL, num_labels=num_labels, output_attentions=False, output_hidden_states=False)\n",
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a03d101dfe494e00ba112d7ea4e3a573",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3781a1a017c84c28b459a36d4422590e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1083389348.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"tf_bert_for_sequence_classification\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bert (TFBertMainLayer)       multiple                  177853440 \n",
            "_________________________________________________________________\n",
            "dropout_37 (Dropout)         multiple                  0         \n",
            "_________________________________________________________________\n",
            "classifier (Dense)           multiple                  1538      \n",
            "=================================================================\n",
            "Total params: 177,854,978\n",
            "Trainable params: 177,854,978\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Zt3_u9X4-IM"
      },
      "source": [
        "O modelo de classificação BERT recebe como entrada um array com dois elementos. O primeiro elemento são os `input_ids` das sequências e o segundo elemento é a máscara de atenção (`attention_mask`) de cada sentença. \n",
        "\n",
        "Para facilitar o treainemtno do modelo definimos uma função que transforma valores de entrada e saída, X e y, para o formato esperado do modelo de classificação."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJlQ1y3G4-IM"
      },
      "source": [
        "def transform_to_model_input(X, y):\n",
        "    encoded_sentences = encode_sentences(X, tokenizer, MAX_SEQUENCE_LENGTH)\n",
        "    X_ = [encoded_sentences['input_ids'], encoded_sentences['attention_mask']]\n",
        "    y_ = tf.convert_to_tensor(y.values, dtype=tf.int16)    \n",
        "    return X_, y_"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrMJRDrr2WDM"
      },
      "source": [
        "Abaixo é realizada a transformação dos dados de treinamento e validação para o formato adequado a ser usado pela função de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOJ6FNPh4-IN"
      },
      "source": [
        "X_train_, y_train_ = transform_to_model_input(X_train, y_train)\n",
        "X_val_  , y_val_  = transform_to_model_input(X_val  , y_val)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfLckI5I4-IN"
      },
      "source": [
        "## Etapa 5 - Treinamento do Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJqZNlZn4-IN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "d6e9c5b2-b542-4268-b20c-51c2a15d3500"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5, epsilon=1e-08, clipnorm=1.0)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-cd28b06ed0ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseCategoricalCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseCategoricalAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsumA9Ns4-IO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf43986d-03f4-4f58-95a1-781e185d4d4b"
      },
      "source": [
        "log_dir='tensorboard_data/tb_bert'\n",
        "model_save_path='bert_model.h5'\n",
        "\n",
        "callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath=model_save_path,save_weights_only=True,monitor='val_loss',mode='min',save_best_only=True)]\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "history = []\n",
        "history_ = model.fit(X_train_, y_train_, batch_size=BATCH_SIZE, epochs=1, validation_data=(X_val_,y_val_), callbacks=callbacks)\n",
        "history.append(history_)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fb752340de0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fb752340de0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7fb76dbebdd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7fb76dbebdd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "443/443 [==============================] - ETA: 0s - loss: 0.4639 - accuracy: 0.7724WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "443/443 [==============================] - 401s 786ms/step - loss: 0.4639 - accuracy: 0.7724 - val_loss: 0.3847 - val_accuracy: 0.8197\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlEkqI9w8Xtz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e3d5463-a2d5-436b-d09e-0e28541ff29b"
      },
      "source": [
        "history_ = model.fit(X_train_, y_train_, batch_size=BATCH_SIZE, epochs=2, validation_data=(X_val_,y_val_), callbacks=callbacks)\n",
        "history.append(history_)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "443/443 [==============================] - 353s 797ms/step - loss: 0.3346 - accuracy: 0.8533 - val_loss: 0.3611 - val_accuracy: 0.8408\n",
            "Epoch 2/2\n",
            "443/443 [==============================] - 355s 802ms/step - loss: 0.2322 - accuracy: 0.9062 - val_loss: 0.3789 - val_accuracy: 0.8601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mtn54b8W6-v-"
      },
      "source": [
        "## Etapa 6 - Avaliação do Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46POhKrK7_EL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c8923bd-3205-41e2-ccb8-61b397b4f08b"
      },
      "source": [
        "best_model = TFBertForSequenceClassification.from_pretrained(PRETRAINED_MODEL, num_labels=num_labels, output_attentions=False, output_hidden_states=False)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5, epsilon=1e-08, clipnorm=1.0)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "best_model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
        "\n",
        "model_save_path='bert_model.h5'\n",
        "best_model.load_weights(model_save_path)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s04id1o0_esS"
      },
      "source": [
        "X_test_ , y_test_  = transform_to_model_input(X_test, y_test)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYQOYDf-Ci9W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbfec9b8-0e99-49a6-b96f-f3919e0b721b"
      },
      "source": [
        "BATCH_SIZE=64\n",
        "loss_test, acc_test = best_model.evaluate(X_test_, y_test_, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "111/111 [==============================] - 1069s 10s/step - loss: 0.3742 - accuracy: 0.8324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8F39KY18ssl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03fae39b-50bd-4524-dc71-7fae477eaad8"
      },
      "source": [
        "print(\"acc_test:\", acc_test)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acc_test: 0.8324385285377502\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text     label  score\n",
              "0     Je ne comprend absolument rien l'application e...  negative      1\n",
              "1     Arnaque, J'ai installée l'application sur mon ...  negative      1\n",
              "2     L'appli crash dès que l'on essaie de rajouter ...  negative      1\n",
              "3     L'application vous propose de fonctionner selo...  negative      1\n",
              "4     Je ne trouve pas ANYDO si pratique ! Il faut p...  negative      1\n",
              "...                                                 ...       ...    ...\n",
              "9542                                  Easy very spécial  positive      5\n",
              "9543                                   For lazy people.  positive      5\n",
              "9544                            Very nice planning app!  positive      5\n",
              "9545  Tres bien comme appli mais quand on met un ren...  positive      5\n",
              "9546                                   Très bonne appli  positive      5\n",
              "\n",
              "[9544 rows x 3 columns]"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Je ne comprend absolument rien l'application e...</td>\n      <td>negative</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Arnaque, J'ai installée l'application sur mon ...</td>\n      <td>negative</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>L'appli crash dès que l'on essaie de rajouter ...</td>\n      <td>negative</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>L'application vous propose de fonctionner selo...</td>\n      <td>negative</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Je ne trouve pas ANYDO si pratique ! Il faut p...</td>\n      <td>negative</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9542</th>\n      <td>Easy very spécial</td>\n      <td>positive</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>9543</th>\n      <td>For lazy people.</td>\n      <td>positive</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>9544</th>\n      <td>Very nice planning app!</td>\n      <td>positive</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>9545</th>\n      <td>Tres bien comme appli mais quand on met un ren...</td>\n      <td>positive</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>9546</th>\n      <td>Très bonne appli</td>\n      <td>positive</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>9544 rows × 3 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "df_fr = pd.read_csv('../data/app_reviews_fr_processed.csv')\n",
        "df_fr = df_fr.dropna()\n",
        "df_fr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  label  score\n",
              "0     Je ne comprend absolument rien l'application e...      0      1\n",
              "1     Arnaque, J'ai installée l'application sur mon ...      0      1\n",
              "2     L'appli crash dès que l'on essaie de rajouter ...      0      1\n",
              "3     L'application vous propose de fonctionner selo...      0      1\n",
              "4     Je ne trouve pas ANYDO si pratique ! Il faut p...      0      1\n",
              "...                                                 ...    ...    ...\n",
              "9542                                  Easy very spécial      1      5\n",
              "9543                                   For lazy people.      1      5\n",
              "9544                            Very nice planning app!      1      5\n",
              "9545  Tres bien comme appli mais quand on met un ren...      1      5\n",
              "9546                                   Très bonne appli      1      5\n",
              "\n",
              "[9544 rows x 3 columns]"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Je ne comprend absolument rien l'application e...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Arnaque, J'ai installée l'application sur mon ...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>L'appli crash dès que l'on essaie de rajouter ...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>L'application vous propose de fonctionner selo...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Je ne trouve pas ANYDO si pratique ! Il faut p...</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9542</th>\n      <td>Easy very spécial</td>\n      <td>1</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>9543</th>\n      <td>For lazy people.</td>\n      <td>1</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>9544</th>\n      <td>Very nice planning app!</td>\n      <td>1</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>9545</th>\n      <td>Tres bien comme appli mais quand on met un ren...</td>\n      <td>1</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>9546</th>\n      <td>Très bonne appli</td>\n      <td>1</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n<p>9544 rows × 3 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "df_fr['label'].replace(to_replace, inplace=True)\n",
        "df_fr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_fr, y_fr = transform_to_model_input(df_fr['text'], df_fr['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 11/150 [=>............................] - ETA: 20:33 - loss: 0.8100 - accuracy: 0.6591"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-30-c34b98113a6f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mloss_test_fr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_test_fr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_fr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_fr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32md:\\Users\\andres\\git_projects\\multi-language-sentiment-analysis\\env\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1487\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1488\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1489\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1490\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1491\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\Users\\andres\\git_projects\\multi-language-sentiment-analysis\\env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\Users\\andres\\git_projects\\multi-language-sentiment-analysis\\env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    922\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[1;32md:\\Users\\andres\\git_projects\\multi-language-sentiment-analysis\\env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\Users\\andres\\git_projects\\multi-language-sentiment-analysis\\env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[1;32md:\\Users\\andres\\git_projects\\multi-language-sentiment-analysis\\env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32md:\\Users\\andres\\git_projects\\multi-language-sentiment-analysis\\env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "BATCH_SIZE=64\n",
        "loss_test_fr, acc_test_fr = best_model.evaluate(X_fr, y_fr, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upVoz9585Rgu"
      },
      "source": [
        "# Conclusão"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9oo-8FPLdUj"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}